{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-07T08:49:17.147421Z","iopub.execute_input":"2022-06-07T08:49:17.148341Z","iopub.status.idle":"2022-06-07T08:49:17.183309Z","shell.execute_reply.started":"2022-06-07T08:49:17.148204Z","shell.execute_reply":"2022-06-07T08:49:17.181947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-06-07T09:13:55.248354Z","iopub.execute_input":"2022-06-07T09:13:55.2488Z","iopub.status.idle":"2022-06-07T09:13:55.254371Z","shell.execute_reply.started":"2022-06-07T09:13:55.248762Z","shell.execute_reply":"2022-06-07T09:13:55.253327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nfrom transformers import TFAutoModelForSequenceClassification\nfrom transformers import AutoTokenizer, AutoConfig\nimport numpy as np\nfrom scipy.special import softmax\n# Preprocess text (username and link placeholders)\ndef preprocess(text):\n    new_text = []\n    for t in text.split(\" \"):\n        t = '@user' if t.startswith('@') and len(t) > 1 else t\n        t = 'http' if t.startswith('http') else t\n        new_text.append(t)\n    return \" \".join(new_text)\nMODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\nconfig = AutoConfig.from_pretrained(MODEL)\n# PT\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL)\n#model.save_pretrained(MODEL)\n\ntext = \"Covid cases are increasing fast!\"\ntext = preprocess(text)\nencoded_input = tokenizer(text, return_tensors='pt')\noutput = model(**encoded_input)\nscores = output[0][0].detach().numpy()\nscores = softmax(scores)\n# # TF\n# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n# model.save_pretrained(MODEL)\n# text = \"Covid cases are increasing fast!\"\n# encoded_input = tokenizer(text, return_tensors='tf')\n# output = model(encoded_input)\n# scores = output[0][0].numpy()\n# scores = softmax(scores)\n# Print labels and scores\nranking = np.argsort(scores)\nranking = ranking[::-1]\nfor i in range(scores.shape[0]):\n    l = config.id2label[ranking[i]]\n    s = scores[ranking[i]]\n    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-07T08:54:23.381747Z","iopub.execute_input":"2022-06-07T08:54:23.382401Z","iopub.status.idle":"2022-06-07T08:54:58.454477Z","shell.execute_reply.started":"2022-06-07T08:54:23.382352Z","shell.execute_reply":"2022-06-07T08:54:58.453766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/stockmarket-sentiment-dataset/stock_data.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T08:56:46.732359Z","iopub.execute_input":"2022-06-07T08:56:46.732809Z","iopub.status.idle":"2022-06-07T08:56:46.787114Z","shell.execute_reply.started":"2022-06-07T08:56:46.732775Z","shell.execute_reply":"2022-06-07T08:56:46.786149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_score = []\nneu_score = []\nneg_score = []\n\nfor index, text in tqdm(df.iterrows(), total=df.shape[0]):\n# for text in tqdm(df['Text'].iterrows()):\n    text = text[0]\n    text = preprocess(text)\n    encoded_input = tokenizer(text, return_tensors='pt')\n    output = model(**encoded_input)\n    scores = output[0][0].detach().numpy()\n    scores = softmax(scores)\n    ranking = np.argsort(scores)\n    ranking = ranking[::-1]\n    neg_score.append(scores[0])\n    neu_score.append(scores[1])\n    pos_score.append(scores[2])\n#     for i in range(scores.shape[0]):\n#         l = config.id2label[ranking[i]]\n#         s = scores[ranking[i]]\n#         print(f\"{i+1}) {l} {np.round(float(s), 4)}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-07T09:15:02.634112Z","iopub.execute_input":"2022-06-07T09:15:02.634545Z","iopub.status.idle":"2022-06-07T09:22:52.939821Z","shell.execute_reply.started":"2022-06-07T09:15:02.634513Z","shell.execute_reply":"2022-06-07T09:22:52.938791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-07T09:22:57.287592Z","iopub.execute_input":"2022-06-07T09:22:57.288026Z","iopub.status.idle":"2022-06-07T09:22:57.294225Z","shell.execute_reply.started":"2022-06-07T09:22:57.287989Z","shell.execute_reply":"2022-06-07T09:22:57.293239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(neg_score), len(neu_score), len(pos_score))","metadata":{"execution":{"iopub.status.busy":"2022-06-07T09:22:59.426589Z","iopub.execute_input":"2022-06-07T09:22:59.427527Z","iopub.status.idle":"2022-06-07T09:22:59.432895Z","shell.execute_reply.started":"2022-06-07T09:22:59.427491Z","shell.execute_reply":"2022-06-07T09:22:59.431781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding these values to the dataframe\ndf['neg_score'] = neg_score\ndf['neu_score'] = neu_score\ndf['pos_score'] = pos_score","metadata":{"execution":{"iopub.status.busy":"2022-06-07T09:25:08.731408Z","iopub.execute_input":"2022-06-07T09:25:08.73234Z","iopub.status.idle":"2022-06-07T09:25:08.747072Z","shell.execute_reply.started":"2022-06-07T09:25:08.7323Z","shell.execute_reply":"2022-06-07T09:25:08.745318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T09:25:31.125163Z","iopub.execute_input":"2022-06-07T09:25:31.125622Z","iopub.status.idle":"2022-06-07T09:25:31.140019Z","shell.execute_reply.started":"2022-06-07T09:25:31.125585Z","shell.execute_reply":"2022-06-07T09:25:31.138801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if rounded off prediction of positive & neutral is equal to Sentiment column\nhit = []\nfor s,p,n,neg in zip(df['Sentiment'], df['pos_score'], df['neu_score'], df['neg_score']):\n    senti = round(p+n)\n    if s == senti:\n        hit.append(1)\n    else:\n        hit.append(0)\nsum(hit)*100/len(hit)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:35:42.62994Z","iopub.execute_input":"2022-06-07T10:35:42.630412Z","iopub.status.idle":"2022-06-07T10:35:42.648033Z","shell.execute_reply.started":"2022-06-07T10:35:42.630375Z","shell.execute_reply":"2022-06-07T10:35:42.646927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using different dataset for Sentiment Analysis","metadata":{}},{"cell_type":"code","source":"df_ = pd.read_csv('../input/stock-market-tweets-data-sentiment-analysis/tweets/tweets_labelled_09042020_16072020.csv',on_bad_lines='skip', sep = ';')\ndf_.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:47:55.121036Z","iopub.execute_input":"2022-06-07T10:47:55.121494Z","iopub.status.idle":"2022-06-07T10:47:55.159224Z","shell.execute_reply.started":"2022-06-07T10:47:55.121458Z","shell.execute_reply":"2022-06-07T10:47:55.158514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:47:56.542086Z","iopub.execute_input":"2022-06-07T10:47:56.542484Z","iopub.status.idle":"2022-06-07T10:47:56.549148Z","shell.execute_reply.started":"2022-06-07T10:47:56.542454Z","shell.execute_reply":"2022-06-07T10:47:56.548103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_['sentiment'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:47:56.868486Z","iopub.execute_input":"2022-06-07T10:47:56.869202Z","iopub.status.idle":"2022-06-07T10:47:56.87695Z","shell.execute_reply.started":"2022-06-07T10:47:56.86916Z","shell.execute_reply":"2022-06-07T10:47:56.876134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:47:57.854115Z","iopub.execute_input":"2022-06-07T10:47:57.854894Z","iopub.status.idle":"2022-06-07T10:47:57.87328Z","shell.execute_reply.started":"2022-06-07T10:47:57.854859Z","shell.execute_reply":"2022-06-07T10:47:57.872395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sentiment2int(word):\n    if word == 'positive':\n        return 1\n    elif word == 'neutral':\n        return 0\n    else:\n        return -1","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:47:58.571574Z","iopub.execute_input":"2022-06-07T10:47:58.572134Z","iopub.status.idle":"2022-06-07T10:47:58.577017Z","shell.execute_reply.started":"2022-06-07T10:47:58.572101Z","shell.execute_reply":"2022-06-07T10:47:58.576195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_['sentiment_num'] = df_['sentiment'].apply(sentiment2int)\ndf_.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:48:00.253672Z","iopub.execute_input":"2022-06-07T10:48:00.254255Z","iopub.status.idle":"2022-06-07T10:48:00.270689Z","shell.execute_reply.started":"2022-06-07T10:48:00.254221Z","shell.execute_reply":"2022-06-07T10:48:00.269814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_score = []\nneu_score = []\nneg_score = []\n\nfor index, text in tqdm(df_.iterrows(), total=df_.shape[0]):\n# for text in tqdm(df['Text'].iterrows()):\n    text = text[2]\n    text = preprocess(text)\n    encoded_input = tokenizer(text, return_tensors='pt')\n    output = model(**encoded_input)\n    scores = output[0][0].detach().numpy()\n    scores = softmax(scores)\n    ranking = np.argsort(scores)\n    ranking = ranking[::-1]\n    neg_score.append(scores[0])\n    neu_score.append(scores[1])\n    pos_score.append(scores[2])\n#     for i in range(scores.shape[0]):\n#         l = config.id2label[ranking[i]]\n#         s = scores[ranking[i]]\n#         print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n\n# adding these values to the dataframe\ndf_['neg_score'] = neg_score\ndf_['neu_score'] = neu_score\ndf_['pos_score'] = pos_score\ndf_.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T10:51:34.03265Z","iopub.execute_input":"2022-06-07T10:51:34.033102Z","iopub.status.idle":"2022-06-07T11:01:38.742548Z","shell.execute_reply.started":"2022-06-07T10:51:34.033066Z","shell.execute_reply":"2022-06-07T11:01:38.74165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if rounded off prediction of positive & neutral is equal to Sentiment column\nhit = []\nfor s,p,n,neg in zip(df_['sentiment_num'], df_['pos_score'], df_['neu_score'], df_['neg_score']):\n    senti_p = round(p)\n    senti_neg = round(neg)\n    senti_neu = round(n)\n    if senti_p>senti_neg && ","metadata":{"execution":{"iopub.status.busy":"2022-06-07T11:20:10.136862Z","iopub.execute_input":"2022-06-07T11:20:10.13734Z","iopub.status.idle":"2022-06-07T11:20:10.259871Z","shell.execute_reply.started":"2022-06-07T11:20:10.137303Z","shell.execute_reply":"2022-06-07T11:20:10.25878Z"},"trusted":true},"execution_count":null,"outputs":[]}]}